# 模型选择
## 训练误差和泛化误差
训练误差：在训练数据上的误差
泛化误差：在新数据上的误差
## k折交叉验证
常用在非大数据集上，将训练数据分割成K块，第i块作为验证数据集，其余的作为训练数据集 ，报告K个验证集误差的平均
，常用K=5或10
## 过拟合和欠拟合
数据复杂度和数据容量之间的关系不挂钩
##### VC维：对于一个分类模型，VC维等于一个最大的数据集的大小，即VC维等价正确分类的最大数据集数目
## 数据复杂度
样本个数、每个样本元素个数、时间空间结构、多样性



# SVM缺点
SVM数据不大的时候很容易解，大的话就不容易了
SVM很平滑，但可调性不强

# dropout 
相当于正则项
将一些输出项随机置为0来控制模型复杂度，常用在多层感知机上
丢弃概率是控制模型复杂度参数
随机置零使得该神经元的梯度为0，不参与更新
dropout会改变输出，网络结构不会改变

# 数值的稳定性
常见问题：梯度消失sigmoid、梯度爆炸ReLu
## 让训练更加稳定
目标：让梯度在合理的范围内
将乘法变加法：ResNet、LSTM 
归一化：梯度归一化，，梯度裁剪
合理的权重初始和激活函数：
#### 让每层的方差是一个常数
将每层的输出和梯度都看作随机变量
将它们的均值和方差都保持一致：使得n_(t-1)y_(t)=1及n_(t)y_(t)=1
Xavier初始
难以满足上述条件，故使得y_(t)(n_(t-1)+n_(t))/2=1 
y_(t)--->第t层的权重的方差
通过输入和输出适配权重，使得输出方差在恒定范围
relu、tanh、sigmoid*4-2  这些函数在0附近近似
#### 总结
合理的权重初始值和激活函数的选取可以提升数值稳定性